# 🎯 Ruby x SerpApi Challenge  

## ✌️ Introduction  
I recently came across **SerpApi**, a web scraper that looks quite interesting. To explore it further, I've decided to **challenge myself** by experimenting with both **Ruby** and **SerpApi**, while also improving how I pick up unfamiliar technologies.  

This repository documents my **daily progress**, learnings, and experiments, including integrating SerpApi with **Ruby on Rails** and potentially deploying on **DigitalOcean**. 🚀  

---

## ⚙️ Technologies Used  
- **Ruby on Rails** 🏗  
- **SerpApi** 🔍  
- **DigitalOcean** (for deployment) ☁  (Perhaps in future)
- **MongoDB** (possibly) 🗄  

---

## 🗓 Challenge Schedule  
📌 **[Click here for the full journal!](https://github.com/xKarinSan/Ruby-SerpApi-Challenge/tree/main/journal)**  

### **🗓 5/3/2025 - Setup & Research**  
- Installing **Ruby on Rails** 🛠  
- Researching **Ruby on Rails** 📚  
- Learning about **SerpApi** 🔎  
- Brainstorming & exploring ideas 💡  
- Experimenting with basic implementations ✨  

### **🗓 6/3/2025 - Ruby Exploration & Ideation**  
- Deep dive into **Ruby (not Rails)**  
- Brainstorming possible project ideas 🤔  

### **🗓 7/3/2025 - Ruby on Rails Exploration**  
- Setting up a basic **Rails project**  
- Implementing **CRUD operations** (Create, Read, Update, Delete) 🔄  

### **🗓 8/3/2025 - Logging & API Integration**  
- Implementing **logging** in Ruby on Rails 📝  
- Integrating **SerpApi** into the project 🔗  

### **🗓 9/3/2025 - Mini Project & Repository Cleanup**  
- Creating a **random project (e.g., an e-commerce scraper)** 🛍  
- Tidying up the repository for better structure 📁  

---

## 📂 Project Contents & How to Run  

### **Prerequisites**  
Ensure you have the following installed on your machine:  
- **Ruby**  
- **Rails**  
- **Bundler** (for managing dependencies)  

### **Getting Started**  
1️⃣ Clone this repository:  
   ```sh
   git clone https://github.com/xKarinSan/Ruby-SerpApi-Challenge.git
   cd Ruby-SerpApi-Challenge
   ```  
   
2️⃣ Navigate to the corresponding **day's folder**:  
   ```sh
   cd day_X
   ```  

3️⃣ Install dependencies:  
   ```sh
   gem install google_search_results dotenv
   ```  

4️⃣ (If required) Set up your **environment variables** in a `.env` file:  
   ```sh
   SERPAPI_API_KEY = <your_serpapi_api_key>
   ```  

5️⃣ Run the script:  
   ```sh
   ruby script_name.rb
   ```  

---

## 📌 Daily Logs  

### **📅 Day 1 (5/3/2025) - Setup**  
No major coding done, just setting up the environment.  

### **📅 Day 2 (6/3/2025) - Object-Oriented Programming (OOP) in Ruby**  
💻 **Run the simulation:**  
```sh
cd day_2
ruby day2.rb
```  

### **📅 Day 3 (7/3/2025) - Ruby API & Full-Stack Boilerplate**  
- Setting up **Rails boilerplate** for full-stack development.  

### **📅 Day 4 (8/3/2025) - SerpAPI Trial**  
🔧 **How to Run:**  
```sh
cd day_4
gem install google_search_results dotenv
echo "SERPAPI_API_KEY=<your_key>" > .env
ruby serpapi_trial.rb
```  

### **📅 Day 5 (9/3/2025) - Continued API Exploration**  
🚀 **Running the script:**  
```sh
cd day_5
gem install google_search_results dotenv
ruby day5.rb
```  

---

## ❤️ Overall
- If I have to learn a programming language again, I will
   - figure out the concepts under the hood as I was once taught that programming languages are different forms of implementation of problem solving logic and concepts.
   - learn the key language more in depth first before learning its framework(s) and under their hood (in this case, I would have spent more time picking up the foundations of Ruby, before picking up Ruby on Rails)
- I would also compare the syntax with the new language against other programming languages that I have already learnt
- First, I would get the code working, then I would refactor (either for code readabilty or performance) and to follow best practices (and understand why the best practice)
- SerpAPI indeed has a lot of potential which is not just limited to gathering data and insights. It can also be used for other purporses such as training models for LLMS, as well as streamlining other business operations like marketing.
- I have learnt the power of web scraping in a deeper level, and understood that it can be used to streamline realtime data acquisition for other purporses such as building of AI agents for purposes such as deciding whether to purchase a product and etc.
- I had fun picking up Ruby from scratch ✌️


## 🚧 Work in Progress  
This project is still **under construction** 🚧! More features and updates will be added as I progress. Stay tuned! 👀  
